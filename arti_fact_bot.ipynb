{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOLUL12izlQ54zGhXT9KjYL"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "–£—Å—Ç–∞–Ω–æ–≤–∏–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏"
   ],
   "metadata": {
    "id": "hYFv2KUuz6Go"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install beautifulsoup4 requests readability-lxml python-telegram-bot httpx python-dotenv\n",
    "!pip install nest_asyncio"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PU6Eo-s2gEd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755616962899,
     "user_tz": -180,
     "elapsed": 11656,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    },
    "outputId": "d644890e-0127-462e-fa2e-a4f6b413f6b7"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
      "Collecting readability-lxml\n",
      "  Downloading readability_lxml-0.8.4.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting python-telegram-bot\n",
      "  Downloading python_telegram_bot-22.3-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.8.3)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from readability-lxml) (5.2.0)\n",
      "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.11/dist-packages (from readability-lxml) (5.4.0)\n",
      "Collecting cssselect (from readability-lxml)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx) (1.3.1)\n",
      "Collecting lxml_html_clean (from lxml[html_clean]->readability-lxml)\n",
      "  Downloading lxml_html_clean-0.4.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Downloading readability_lxml-0.8.4.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_telegram_bot-22.3-py3-none-any.whl (717 kB)\n",
      "\u001B[2K   \u001B[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001B[0m \u001B[32m717.1/717.1 kB\u001B[0m \u001B[31m19.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading lxml_html_clean-0.4.2-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: python-dotenv, lxml_html_clean, cssselect, readability-lxml, python-telegram-bot\n",
      "Successfully installed cssselect-1.3.0 lxml_html_clean-0.4.2 python-dotenv-1.1.1 python-telegram-bot-22.3 readability-lxml-0.8.4.1\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ],
   "metadata": {
    "id": "-tsPdMts2phL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755616964439,
     "user_tz": -180,
     "elapsed": 16,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import userdata\n",
    "DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')\n",
    "TELEGRAM_BOT_TOKEN = userdata.get('TELEGRAM_BOT_TOKEN')"
   ],
   "metadata": {
    "id": "Blb3qaggBTwn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755618572880,
     "user_tz": -180,
     "elapsed": 934,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. –ü–∞—Ä—Å–µ—Ä —Å—Ç–∞—Ç–µ–π"
   ],
   "metadata": {
    "id": "wErVaPIrzW_y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from readability import Document\n",
    "import re\n",
    "\n",
    "def extract_article_text(url: str) -> str:\n",
    "    \"\"\"\n",
    "    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ –∏–∑ URL\n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        doc = Document(response.text)\n",
    "        soup = BeautifulSoup(doc.summary(), 'html.parser')\n",
    "\n",
    "        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤\n",
    "        clean_text = soup.get_text()\n",
    "        clean_text = re.sub(r'\\s+', ' ', clean_text).strip()\n",
    "\n",
    "        return clean_text[:5000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –¥–ª—è –ø—Ä–æ—Ç–æ—Ç–∏–ø–∞\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}\")\n",
    "        return None\n"
   ],
   "metadata": {
    "id": "Mgzb7FrV0M8U",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755616981261,
     "user_tz": -180,
     "elapsed": 785,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–∞—Ä—Å–µ—Ä\n",
    "test_url = \"https://habr.com/ru/articles/789322/\"\n",
    "text = extract_article_text(test_url)\n",
    "print(f\"–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: {len(text) if text else 0}\")\n",
    "if text:\n",
    "    print(f\"–ü—Ä–µ–≤—å—é: {text[:200]}...\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PlSRNpf73li7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755617189679,
     "user_tz": -180,
     "elapsed": 1599,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    },
    "outputId": "c02690ac-2162-4f07-d3ac-751f77f4f1d6"
   },
   "execution_count": 6,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "–ò–∑–≤–ª–µ—á–µ–Ω–æ —Å–∏–º–≤–æ–ª–æ–≤: 5000\n",
      "–ü—Ä–µ–≤—å—é: –û–±—â–∏–π –≤–∏–¥ –°–ê–ü–† Delta Design –¥–ª—è .NET 6–°–ê–ü–† Delta Design ‚Äî —ç—Ç–æ –æ—Ç–µ—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è ECAD —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —ç–ª–µ–∫—Ç—Ä–æ–Ω–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –æ—Ç –∫–æ–º–ø–∞–Ω–∏–∏ –≠–†–ï–ú–ï–ö–°, –∏–º–µ—é—â–∞—è –¥–µ—Å—è—Ç–∏–ª–µ—Ç–Ω—é—é –∏—Å—Ç–æ—Ä–∏—é. –í–µ—Ä—Å–∏—è Delta Design...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. LLM-–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è (DeepSeek API)"
   ],
   "metadata": {
    "id": "FjwMp7R43sM1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import httpx\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "class DeepSeekAnalyzer:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = \"https://api.deepseek.com/v1/chat/completions\"\n",
    "\n",
    "    async def analyze_article(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ —Å –ø–æ–º–æ—â—å—é DeepSeek API\n",
    "        \"\"\"\n",
    "        prompt = \"\"\"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é –∏ –≤–µ—Ä–Ω–∏ JSON —Å–æ —Å–ª–µ–¥—É—é—â–∏–º–∏ –ø–æ–ª—è–º–∏:\n",
    "        - tags: —Å–ø–∏—Å–æ–∫ –∏–∑ 3-5 —Ç–µ–≥–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, [\"Python\", \"API\", \"Machine Learning\"])\n",
    "        - summary: –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑ –Ω–∞ —Ä—É—Å—Å–∫–æ–º (50-100 —Å–ª–æ–≤)\n",
    "        - thesis: –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∑–∏—Å —Å—Ç–∞—Ç—å–∏ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)\n",
    "        - category: –∫–∞—Ç–µ–≥–æ—Ä–∏—è (Programming, DevOps, Data Science, AI, Web Development, Other)\n",
    "\n",
    "        –¢–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏: {text}\n",
    "\n",
    "        –û—Ç–≤–µ—Ç —Ç–æ–ª—å–∫–æ –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞.\"\"\".replace(\"{text}\", text[:3000])\n",
    "\n",
    "        try:\n",
    "            async with httpx.AsyncClient(timeout=30.0) as client:\n",
    "                response = await client.post(\n",
    "                    self.base_url,\n",
    "                    headers={\n",
    "                        \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "                        \"Content-Type\": \"application/json\"\n",
    "                    },\n",
    "                    json={\n",
    "                        \"model\": \"deepseek-chat\",\n",
    "                        \"messages\": [\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": \"–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –≤–∞–ª–∏–¥–Ω—ã–º JSON.\"\n",
    "                            },\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": prompt\n",
    "                            }\n",
    "                        ],\n",
    "                        \"temperature\": 0.3,\n",
    "                        \"max_tokens\": 1000\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    result = response.json()\n",
    "                    content = result[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "                    # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞\n",
    "                    json_match = re.search(r'\\{[\\s\\S]*\\}', content)\n",
    "                    if json_match:\n",
    "                        return json.loads(json_match.group())\n",
    "                    return {\"error\": \"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON –æ—Ç–≤–µ—Ç\"}\n",
    "\n",
    "                else:\n",
    "                    return {\"error\": f\"API error: {response.status_code}\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Exception: {str(e)}\"}\n"
   ],
   "metadata": {
    "id": "xUDdSKvO3vOG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755617207328,
     "user_tz": -180,
     "elapsed": 115,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. –û—Å–Ω–æ–≤–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫"
   ],
   "metadata": {
    "id": "dTDH8N9uCbvA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class ArticleProcessor:\n",
    "    def __init__(self, api_key: str):\n",
    "        self.analyzer = DeepSeekAnalyzer(api_key)\n",
    "\n",
    "    async def process_url(self, url: str) -> dict:\n",
    "        \"\"\"\n",
    "        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL\n",
    "        \"\"\"\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç\n",
    "        text = extract_article_text(url)\n",
    "        if not text:\n",
    "            return {\"error\": \"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏\"}\n",
    "\n",
    "        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ LLM\n",
    "        analysis = await self.analyzer.analyze_article(text)\n",
    "\n",
    "        if \"error\" not in analysis:\n",
    "            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "            result = {\n",
    "                \"url\": url,\n",
    "                \"text_preview\": text[:500] + \"...\" if len(text) > 500 else text,\n",
    "                \"analysis\": analysis\n",
    "            }\n",
    "            return result\n",
    "        else:\n",
    "            return {\"error\": analysis[\"error\"]}\n"
   ],
   "metadata": {
    "id": "466l6L6x8Wfc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755618878703,
     "user_tz": -180,
     "elapsed": 45,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã"
   ],
   "metadata": {
    "id": "wUOpWw_ECoo5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä\n",
    "processor = ArticleProcessor(DEEPSEEK_API_KEY)\n",
    "\n",
    "# %%\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "test_urls = [\n",
    "    \"https://habr.com/ru/articles/789322/\",  # –ü—Ä–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    \"https://habr.com/ru/articles/789150/\",  # –ü—Ä–æ DevOps\n",
    "]\n",
    "\n",
    "# %%\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É\n",
    "async def test_processing():\n",
    "    for url in test_urls:\n",
    "        print(f\"\\nüîó –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {url}\")\n",
    "        result = await processor.process_url(url)\n",
    "\n",
    "        if \"error\" in result:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞: {result['error']}\")\n",
    "        else:\n",
    "            print(\"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!\")\n",
    "            print(f\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:\")\n",
    "            print(f\"   –¢–µ–≥–∏: {', '.join(result['analysis'].get('tags', []))}\")\n",
    "            print(f\"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result['analysis'].get('category', 'Unknown')}\")\n",
    "            print(f\"   –ü–µ—Ä–µ—Å–∫–∞–∑: {result['analysis'].get('summary', '')[:100]}...\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç\n",
    "await test_processing()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGCDbEOTCuYp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620203385,
     "user_tz": -180,
     "elapsed": 4925,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    },
    "outputId": "f0a1a83c-3a57-435d-c46e-f5cbe77e917a"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üîó –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: https://habr.com/ru/articles/789322/\n",
      "‚ùå –û—à–∏–±–∫–∞: API error: 402\n",
      "\n",
      "üîó –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: https://habr.com/ru/articles/789150/\n",
      "‚ùå –û—à–∏–±–∫–∞: API error: 402\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Telegram-–±–æ—Ç"
   ],
   "metadata": {
    "id": "OHoRL2BtDUUt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from telegram import Update\n",
    "from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes\n",
    "import logging\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TelegramBot:\n",
    "    def __init__(self, token: str, processor: ArticleProcessor):\n",
    "        self.token = token\n",
    "        self.processor = processor\n",
    "        self.application = Application.builder().token(token).build()\n",
    "\n",
    "        # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏\n",
    "        self.application.add_handler(CommandHandler(\"start\", self.start_handler))\n",
    "        self.application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.message_handler))\n",
    "\n",
    "    async def start_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "        \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start\"\"\"\n",
    "        welcome_text = \"\"\"\n",
    "        ü§ñ –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ ArtiFact Prototype!\n",
    "\n",
    "        –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Å—Å—ã–ª–∫—É –Ω–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é (Habr, Medium, arXiv –∏ –¥—Ä.), –∏ —è:\n",
    "        - –ò–∑–≤–ª–µ–∫—É –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–≥–∏\n",
    "        - –°–¥–µ–ª–∞—é –∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑\n",
    "        - –û–ø—Ä–µ–¥–µ–ª—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é\n",
    "\n",
    "        –ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ URL! üöÄ\n",
    "        \"\"\"\n",
    "        await update.message.reply_text(welcome_text)\n",
    "\n",
    "    async def message_handler(self, update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
    "        \"\"\"–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π\"\"\"\n",
    "        text = update.message.text\n",
    "\n",
    "        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç URL\n",
    "        if not text.startswith(('http://', 'https://')):\n",
    "            await update.message.reply_text(\"üìé –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞–ª–∏–¥–Ω—ã–π URL (–Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å http:// –∏–ª–∏ https://)\")\n",
    "            return\n",
    "\n",
    "        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
    "        status_msg = await update.message.reply_text(\"‚è≥ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç–∞—Ç—å—é...\")\n",
    "\n",
    "        try:\n",
    "            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç—å—é\n",
    "            result = await self.processor.process_url(text)\n",
    "\n",
    "            if \"error\" in result:\n",
    "                await status_msg.edit_text(f\"‚ùå –û—à–∏–±–∫–∞: {result['error']}\")\n",
    "                return\n",
    "\n",
    "            analysis = result['analysis']\n",
    "\n",
    "            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç\n",
    "            response = f\"\"\"\n",
    "            üìä **–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞**\n",
    "\n",
    "            üîñ **–¢–µ–≥–∏:** {', '.join(analysis.get('tags', []))}\n",
    "            üìÅ **–ö–∞—Ç–µ–≥–æ—Ä–∏—è:** {analysis.get('category', 'Unknown')}\n",
    "\n",
    "            üìù **–ö—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑:**\n",
    "            {analysis.get('summary', '')}\n",
    "\n",
    "            üí° **–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∑–∏—Å:**\n",
    "            {analysis.get('thesis', '')}\n",
    "            \"\"\"\n",
    "\n",
    "            await status_msg.edit_text(response)\n",
    "\n",
    "        except Exception as e:\n",
    "            await status_msg.edit_text(f\"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"–ó–∞–ø—É—Å–∫–∞–µ—Ç –±–æ—Ç–∞\"\"\"\n",
    "        logger.info(\"–ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞...\")\n",
    "        self.application.run_polling()\n",
    "\n"
   ],
   "metadata": {
    "id": "kKFrtgAoC0wI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755619111291,
     "user_tz": -180,
     "elapsed": 240,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏"
   ],
   "metadata": {
    "id": "YgNNfiAOD2-D"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.1 –õ–æ–∫–∞–ª—å–Ω–∞—è LLM —á–µ—Ä–µ–∑ Ollama"
   ],
   "metadata": {
    "id": "bfakNNCNFS-T"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class OllamaAnalyzer:\n",
    "    async def analyze_article(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–π LLM —á–µ—Ä–µ–∑ Ollama\n",
    "        \"\"\"\n",
    "        try:\n",
    "            async with httpx.AsyncClient(timeout=60.0) as client:\n",
    "                response = await client.post(\n",
    "                    \"http://localhost:11434/api/generate\",\n",
    "                    json={\n",
    "                        \"model\": \"mistral\",  # –∏–ª–∏ \"llama3\", \"mixtral\"\n",
    "                        \"prompt\": f\"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Å—Ç–∞—Ç—å—é –∏ –≤–µ—Ä–Ω–∏ JSON —Å –ø–æ–ª—è–º–∏: tags (—Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤), summary (–∫—Ä–∞—Ç–∫–∏–π –ø–µ—Ä–µ—Å–∫–∞–∑), thesis (–æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∑–∏—Å). –¢–µ–∫—Å—Ç: {text[:2000]}\",\n",
    "                        \"format\": \"json\",\n",
    "                        \"stream\": False\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    return response.json().get(\"response\", {})\n",
    "                else:\n",
    "                    return {\"error\": f\"Ollama error: {response.status_code}\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Ollama exception: {str(e)}\"}"
   ],
   "metadata": {
    "id": "7_SQwFzbECH3",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755619277629,
     "user_tz": -180,
     "elapsed": 44,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### –í–∞—Ä–∏–∞–Ω—Ç 6.2: Hugging Face Inference API"
   ],
   "metadata": {
    "id": "IZr1D_55GTRM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "class HuggingFaceAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.api_url = \"https://api-inference.huggingface.co/models\"\n",
    "\n",
    "    async def analyze_article(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏ —Å –ø–æ–º–æ—â—å—é –±–µ—Å–ø–ª–∞—Ç–Ω–æ–≥–æ HF API\n",
    "        \"\"\"\n",
    "        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏\n",
    "        try:\n",
    "            async with httpx.AsyncClient(timeout=60.0) as client:\n",
    "                # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é\n",
    "                summary_response = await client.post(\n",
    "                    f\"{self.api_url}/facebook/bart-large-cnn\",\n",
    "                    headers={\"Authorization\": \"Bearer hf_your_token_here\"},\n",
    "                    json={\"inputs\": text[:1024]}\n",
    "                )\n",
    "\n",
    "                if summary_response.status_code == 200:\n",
    "                    summary = summary_response.json()[0]['summary_text']\n",
    "\n",
    "                    # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–≥–æ–≤ (–Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤)\n",
    "                    tags = self.extract_tags(text)\n",
    "\n",
    "                    return {\n",
    "                        \"tags\": tags,\n",
    "                        \"summary\": summary,\n",
    "                        \"thesis\": summary[:150] + \"...\",  # –£–∫–æ—Ä–æ—á–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è\n",
    "                        \"category\": self.detect_category(text)\n",
    "                    }\n",
    "                else:\n",
    "                    return {\"error\": f\"HF API error: {summary_response.status_code}\"}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Exception: {str(e)}\"}\n",
    "\n",
    "    def extract_tags(self, text: str) -> list:\n",
    "        \"\"\"–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–≥–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º\"\"\"\n",
    "        keywords = {\n",
    "            'python': ['python', 'django', 'flask'],\n",
    "            'javascript': ['javascript', 'node', 'react', 'vue'],\n",
    "            'devops': ['docker', 'kubernetes', 'ci/cd', 'devops'],\n",
    "            'ai': ['ai', 'machine learning', 'ml', 'neural network'],\n",
    "            'web': ['web', 'http', 'api', 'rest'],\n",
    "            'data': ['data', 'database', 'sql', 'nosql']\n",
    "        }\n",
    "\n",
    "        found_tags = []\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        for tag, words in keywords.items():\n",
    "            if any(word in text_lower for word in words):\n",
    "                found_tags.append(tag)\n",
    "\n",
    "        return found_tags[:3] or [\"technology\"]\n",
    "\n",
    "    def detect_category(self, text: str) -> str:\n",
    "        \"\"\"–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏\"\"\"\n",
    "        text_lower = text.lower()\n",
    "\n",
    "        if any(word in text_lower for word in ['python', 'java', 'c++', 'programming']):\n",
    "            return \"Programming\"\n",
    "        elif any(word in text_lower for word in ['docker', 'kubernetes', 'devops', 'deploy']):\n",
    "            return \"DevOps\"\n",
    "        elif any(word in text_lower for word in ['ai', 'machine learning', 'neural', 'deep learning']):\n",
    "            return \"AI\"\n",
    "        elif any(word in text_lower for word in ['web', 'http', 'browser', 'frontend']):\n",
    "            return \"Web Development\"\n",
    "        else:\n",
    "            return \"Technology\"\n"
   ],
   "metadata": {
    "id": "_bh0On1TGpRI",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620031411,
     "user_tz": -180,
     "elapsed": 23647,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class AltArticleProcessor:\n",
    "    def __init__(self):\n",
    "        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –ø–æ –ø–æ—Ä—è–¥–∫—É\n",
    "        self.analyzers = [\n",
    "            # LocalAnalyzer(),  # –ü–µ—Ä–≤—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç - –ª–æ–∫–∞–ª—å–Ω—ã–π\n",
    "            HuggingFaceAnalyzer(),  # –í—Ç–æ—Ä–æ–π - HF API\n",
    "            # OpenRouterAnalyzer()  # –¢—Ä–µ—Ç–∏–π - OpenRouter\n",
    "        ]\n",
    "\n",
    "    async def process_url(self, url: str) -> dict:\n",
    "        \"\"\"\n",
    "        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL\n",
    "        \"\"\"\n",
    "        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç\n",
    "        text = extract_article_text(url)\n",
    "        if not text:\n",
    "            return {\"error\": \"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç —Å—Ç–∞—Ç—å–∏\"}\n",
    "\n",
    "        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –ø–æ–∫–∞ –æ–¥–∏–Ω –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç\n",
    "        for analyzer in self.analyzers:\n",
    "            try:\n",
    "                analysis = await analyzer.analyze_article(text)\n",
    "                if \"error\" not in analysis:\n",
    "                    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç\n",
    "                    result = {\n",
    "                        \"url\": url,\n",
    "                        \"text_preview\": text[:500] + \"...\" if len(text) > 500 else text,\n",
    "                        \"analysis\": analysis\n",
    "                    }\n",
    "                    return result\n",
    "            except Exception as e:\n",
    "                print(f\"–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä {type(analyzer).__name__} failed: {e}\")\n",
    "                continue\n",
    "\n",
    "        return {\"error\": \"–í—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏\"}"
   ],
   "metadata": {
    "id": "_R661gDdHPUh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620176483,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "s_edXSPaHhEj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä\n",
    "processor = AltArticleProcessor()\n",
    "\n",
    "# %%\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–µ URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "test_urls = [\n",
    "    \"https://habr.com/ru/articles/789322/\",  # –ü—Ä–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    \"https://habr.com/ru/articles/789150/\",  # –ü—Ä–æ DevOps\n",
    "]\n",
    "\n",
    "# %%\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É\n",
    "async def test_processing():\n",
    "    for url in test_urls:\n",
    "        print(f\"\\nüîó –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {url}\")\n",
    "        result = await processor.process_url(url)\n",
    "\n",
    "        if \"error\" in result:\n",
    "            print(f\"‚ùå –û—à–∏–±–∫–∞: {result['error']}\")\n",
    "        else:\n",
    "            print(\"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!\")\n",
    "            print(f\"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç:\")\n",
    "            print(f\"   –¢–µ–≥–∏: {', '.join(result['analysis'].get('tags', []))}\")\n",
    "            print(f\"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {result['analysis'].get('category', 'Unknown')}\")\n",
    "            print(f\"   –ü–µ—Ä–µ—Å–∫–∞–∑: {result['analysis'].get('summary', '')[:100]}...\")\n",
    "\n",
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç\n",
    "await test_processing()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620229409,
     "user_tz": -180,
     "elapsed": 2491,
     "user": {
      "displayName": "–û–ª–µ–≥ –ü–∞–≤–ª–æ–≤",
      "userId": "13525531702128177385"
     }
    },
    "outputId": "ddfe5d9e-4c6e-4376-d36d-d9ab54358df5",
    "id": "tNiSIOd3HncY"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "üîó –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: https://habr.com/ru/articles/789322/\n",
      "‚ùå –û—à–∏–±–∫–∞: –í—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏\n",
      "\n",
      "üîó –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: https://habr.com/ru/articles/789150/\n",
      "‚ùå –û—à–∏–±–∫–∞: –í—Å–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8. –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞"
   ],
   "metadata": {
    "id": "rQsXOU34Dljs"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –∑–∞–ø—É—Å–∫\n",
    "processor = ArticleProcessor(DEEPSEEK_API_KEY)\n",
    "bot = TelegramBot(TELEGRAM_BOT_TOKEN, processor)\n",
    "\n",
    "# # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞\n",
    "print(\"–ó–∞–ø—É—Å–∫–∞–µ–º Telegram-–±–æ—Ç–∞...\")\n",
    "bot.run()"
   ],
   "metadata": {
    "id": "cy4S5oW_CxA8"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
